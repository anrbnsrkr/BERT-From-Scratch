{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5602674a-4269-4413-b116-040a252e40ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "import TrainFunctions\n",
    "import BertEnchoder\n",
    "from transformers import BertTokenizer\n",
    "import importlib\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82703392-622e-40dd-86d1-fd935eddc3fa",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = TrainFunctions.Load_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b886a8-49f0-4b29-b24e-89df0f343496",
   "metadata": {},
   "outputs": [],
   "source": [
    "lebels = list(data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c12b5a3-2064-4883-b1a4-f48db8cff9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask', 'labels']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lebels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc780643-8474-4182-a153-9992f424eae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1756584/1756584 [00:34<00:00, 50740.13it/s]\n",
      "100%|██████████| 1756584/1756584 [00:34<00:00, 50383.55it/s]\n",
      "100%|██████████| 1756584/1756584 [00:34<00:00, 51340.37it/s]\n",
      "100%|██████████| 1756584/1756584 [00:34<00:00, 51342.33it/s]\n",
      "100%|██████████| 1742305/1742305 [00:33<00:00, 51289.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dl_data = []\n",
    "for i, d in enumerate(data):\n",
    "    dl_data.append(TrainFunctions.cvt_dict_to_TensorDataset(d,batch_size=20,lebels=lebels))\n",
    "    data[i] = None\n",
    "    d = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc9c7d0-50b2-4212-a902-0be6a149363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lis = dl_data[1:]\n",
    "test_dl = dl_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa95032-310c-40e1-9afb-edb700b0f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8b239a-5178-4e41-95b0-75ba3ca71613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e98623-7322-494a-804d-600eca3e01cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba57ee88-2d34-439c-bc7d-a05bfba12409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57fdf01-fcec-4ef2-82f1-d2183ab3951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03d687e6-e5e1-4dea-bdb4-c6d6d0724a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderOnly(\n",
      "  (Embead): BERTmbeadings(\n",
      "    (Embead): Embedding(30522, 240, padding_idx=0)\n",
      "    (PosEmbead): Embedding(128, 240)\n",
      "    (SegEmbeading): Embedding(2, 240)\n",
      "  )\n",
      "  (Blocks): ModuleList(\n",
      "    (0-11): 12 x EncoderBLock(\n",
      "      (Attantion): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=240, out_features=240, bias=True)\n",
      "      )\n",
      "      (MLP): Sequential(\n",
      "        (0): Linear(in_features=240, out_features=960, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=960, out_features=240, bias=True)\n",
      "      )\n",
      "      (Norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "      (Norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "      (Drop): Dropout(p=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (MLM): MaskedLangModeling(\n",
      "    (MLP): Sequential(\n",
      "      (0): Linear(in_features=240, out_features=240, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Linear(in_features=240, out_features=30522, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (NSP): NextSentPred(\n",
      "    (MLP): Sequential(\n",
      "      (0): Linear(in_features=240, out_features=240, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Linear(in_features=240, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BertEnchoder.EncoderOnly(vocabSize=tokenizer.vocab_size, embedDim=240, \n",
    "                                 numHeads=12,numLayers=12,numPosEmbeading=128,\n",
    "                                 numSegEmbeading=2,padIdx=0)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ce51f6-0386-4dbc-9252-3561363dac6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350606\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for dl in train_lis:\n",
    "    x += len(dl)\n",
    "print(x)\n",
    "\n",
    "epochs = 1\n",
    "criterion_nsp = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "ignore_idx = -100\n",
    "criterion_mlm = torch.nn.CrossEntropyLoss(ignore_index=ignore_idx)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay=1e-2)\n",
    "\n",
    "steps = epochs * x\n",
    "w_steps = max(1, int(steps * 0.1))\n",
    "c_steps = max(1,(steps - w_steps))\n",
    "\n",
    "Cosine = CosineAnnealingLR(optimizer,T_max=c_steps,eta_min= 1e-7)\n",
    "\n",
    "warmup = LinearLR(optimizer,start_factor=1e-3, total_iters=w_steps)\n",
    "\n",
    "scheduler = SequentialLR(optimizer,[warmup, Cosine], milestones=[w_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90cba2a5-8645-497b-ab4b-c57f6dde90eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training :\n",
      "Data Loader No.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 35059/87830 [31:07<47:39, 18.46it/s, Train Loss =6.944662, accu=0.466392, masked_accu=0.125161, NSP_accu=0.760643, lr=0.0001]/home/bulu/anaconda3/envs/NLP/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:198: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "100%|██████████| 87830/87830 [1:22:41<00:00, 17.70it/s, Train Loss =5.726731, accu=0.621678, masked_accu=0.226672, NSP_accu=0.831900, lr=9.33e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss, accu, masked_accu, NSP_accu:  (5.726731323924407, 0.6216782162495226, 0.22667181998498992, 0.8318998692917617)\n",
      "Testing :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87830/87830 [35:18<00:00, 41.46it/s, Train Loss =1.800904, accu=0.775870, masked_accu=0.350641, NSP_accu=0.925240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Model Saved at epoch :1\n",
      "Accu Model Saved at epoch :1\n",
      "Masked Accu Model Saved at epoch :1\n",
      "NSP Accu Model Saved at epoch :1\n",
      "Test Loss, accu, masked_accu, NSP_accu:  (1.8009042887773625, 0.7758695864031776, 0.35064106500674136, 0.9252401251519996)\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(TrainFunctions)\n",
    "loss_list, model = TrainFunctions.train(model=model, dl_lis= train_lis[:1], mask_id= 103, p= 0.2,vocab_size = tokenizer.vocab_size,\n",
    "                     criterion_mlm=criterion_mlm, ignore_idx = ignore_idx,criterion_nsp=criterion_nsp, optimizer=optimizer, \n",
    "                     seheduler=scheduler, clip_grad=0.5, test_dl=test_dl, device=device, epochs=1, enable_bf16 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc86d315-29d8-4168-b38e-224e132779aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training :\n",
      "Data Loader No.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87830/87830 [1:21:40<00:00, 17.92it/s, Train Loss =3.972474, accu=0.802307, masked_accu=0.372531, NSP_accu=0.944815, lr=5.85e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss, accu, masked_accu, NSP_accu:  (3.9724736111427132, 0.8023069651806787, 0.37253081276222577, 0.9448150501200057)\n",
      "Data Loader No.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87830/87830 [1:21:35<00:00, 17.94it/s, Train Loss =3.626934, accu=0.831821, masked_accu=0.405293, NSP_accu=0.965567, lr=1.77e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss, accu, masked_accu, NSP_accu:  (3.626933663819491, 0.8318212098737863, 0.40529316941833826, 0.965567260091177)\n",
      "Data Loader No.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87116/87116 [1:21:22<00:00, 17.84it/s, Train Loss =3.501225, accu=0.841038, masked_accu=0.417963, NSP_accu=0.973344, lr=1e-07]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss, accu, masked_accu, NSP_accu:  (3.5012248085136175, 0.8410380573435388, 0.41796318981972075, 0.9733439323195422)\n",
      "Testing :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87830/87830 [35:39<00:00, 41.04it/s, Train Loss =1.064270, accu=0.846259, masked_accu=0.428372, NSP_accu=0.976187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Model Saved at epoch :1\n",
      "Accu Model Saved at epoch :1\n",
      "Masked Accu Model Saved at epoch :1\n",
      "NSP Accu Model Saved at epoch :1\n",
      "Test Loss, accu, masked_accu, NSP_accu:  (1.0642704053627587, 0.8462585042545269, 0.42837166396634463, 0.9761873044500007)\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(TrainFunctions)\n",
    "loss_list, model = TrainFunctions.train(model=model, dl_lis= train_lis[1:], mask_id= 103, p= 0.2,vocab_size = tokenizer.vocab_size,\n",
    "                     criterion_mlm=criterion_mlm, ignore_idx = ignore_idx,criterion_nsp=criterion_nsp, optimizer=optimizer, \n",
    "                     seheduler=scheduler, clip_grad=0.5, test_dl=test_dl, device=device, epochs=1, enable_bf16 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58769724-7ed2-4e16-b732-ea87b3faf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TrainTest_Loss_Accu.pkl\", 'wb') as f:\n",
    "    pickle.dump(obj=loss_list, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03b2d7-7bad-4fd8-b523-1197e9756b20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
